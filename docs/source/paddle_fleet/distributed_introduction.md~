# 欢迎关注大规模深度学习技术

近十年来，深度学习技术不断刷新视觉、自然语言、语音、搜索、推荐等领域各种任务的记录。这其中的原因，用一个关键词描述就是“大规模”。大规模的数据使得模型有足够的知识可以记忆，大规模参数量的模型使得模型本身有能力记忆更多的数据，大规模高性能的算力（以GPU为典型代表）使得模型的训练速度有百倍甚至千倍的提升。数据、模型、算力的发展催生了大规模深度学习这个领域，如何进行多机任务的拆分、如何配置集群训练资源、如何平衡训练速度和收敛速度、如何训练单机无法训练的模型、弹性训练与容错等都是这个方向重点研究的问题。

# 飞桨分布式训练提供的核心价值

- 源自产业实践：
  - 飞桨的分布式训练技术源自百度的业务实践，是经过各种类型业务进行精细化打磨的产品，在分布式训练的功能、性能、稳定性方面都有较好的保障。
  
- 完备的并行模式：
  - 数据并行：针对产业界最常用的数据并行模式，飞桨针对实际业务需求重点打磨多项技术，包括；飞桨提供集合通信架构和参数服务器架构两种方式，支持工业实践中常见的同步训练和异步训练的机制，并提供收敛效果有保障的分布式优化算法。
  - 流水线并行：面向异构硬件，流水线并行能够将模型计算部分拆分到不同硬件并充分流水线化，从而大规模提升异构硬件的整体利用率。
  - 模型并行：对于超大规模分类问题，飞桨提供计算与存储同时并行的模型并行，解决单GPU无法解决的问题。
  
- 面向云端场景的并行训练组件：
  - 飞桨针对集群网络环境、硬件设备比较低配的场景也提供多种实用的并行策略和优化算法。

# 开始你的分布式训练之旅

- 我们推荐您直接根据[主页](../index.html)，按照章节顺序逐个浏览学习，如果有任何疑问都可以在[Paddle](https://github.com/PaddlePaddle/Paddle)、[FleetX](https://github.com/PaddlePaddle/FleetX/)提交issue提问
- 对于高频出现的问题，我们会定期整理相关内容到[FAQ](fleet_user_faq_cn.html)
- 如果想最低成本的了解飞桨的分布式训练，我们推荐阅读[静态图并行训练快速开始](fleet_static_quick_start.html)和[动态图并行训练快速开始](fleet_dygraph_quick_start.html)
- 如果您已经开始使用GPU进行多机多卡训练，[数据并行同步训练实践](fleet_collective_training_practices_cn.html)是很好的参考。
- 信息检索、推荐系统领域常用的并行训练方式，可以参考[使用Fleet进行参数服务器训练](fleet_ps_sync_and_async_cn.html)。
- 如果您在公有云上跑自己的GPU多卡任务，性能不佳，[优化低配网络的分布式GPU训练](fleet_on_cloud.html)是调优性能的好方法

# RoadMap

- 我们也会推送大规模深度学习技术领域最前沿的技术到这里
  - 近期：千亿规模模型参数的GPU多机多卡训练，敬请期待

